{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import properscoring as prscore\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess  the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('power_weather_data.csv')\n",
    "\n",
    "# csv file MUST contain 'date' and 'Power' fields\n",
    "# optional: weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['date'].apply(lambda x: x.hour )\n",
    "df['month'] = df['date'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = df['Power']\n",
    "\n",
    "PowerData = pd.concat([P.shift(3), P.shift(2), P.shift(1)], axis=1)\n",
    "PowerData.columns = ['t-45', 't-30', 't-15']\n",
    "\n",
    "df = pd.concat([df, PowerData.reindex(df.index)], axis=1)\n",
    "    \n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = [['2018-03-01', '2019-03-15']]\n",
    "\n",
    "val_days = 14\n",
    "\n",
    "n_points_day = 4 * 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for w in weeks:\n",
    "    \n",
    "    w_start = datetime.strptime(w[0]+\" 00:00\", '%Y-%m-%d %H:%M')\n",
    "    w_end = datetime.strptime(w[1]+\" 23:59\", '%Y-%m-%d %H:%M')\n",
    "    \n",
    "    dfs.append(df[(df['date'] > w_start) & (df['date'] < w_end)])\n",
    "    \n",
    "n_sets = len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = []\n",
    "X_test_ = []\n",
    "y_train_ = []\n",
    "y_test_ = []\n",
    "\n",
    "x_scaler = []\n",
    "y_scaler = []\n",
    "\n",
    "t_train = []\n",
    "t_test = []\n",
    "\n",
    "for i in range(n_sets):\n",
    "\n",
    "    train = dfs[i][:int(-n_points_day*val_days)]\n",
    "    test = dfs[i][int(-n_points_day*val_days):]\n",
    "    \n",
    "    X_tr = train.drop(['Power','date'], axis=1).values\n",
    "    X_t = test.drop(['Power','date'], axis=1).values\n",
    "    \n",
    "    y_tr = train['Power'].values\n",
    "    y_t = test['Power'].values\n",
    "    \n",
    "    x_sc = MinMaxScaler()\n",
    "    y_sc = MinMaxScaler()\n",
    "#     x_sc = StandardScaler()\n",
    "#     y_sc = StandardScaler()\n",
    "    x_sc.fit(X_tr)\n",
    "    y_sc.fit(y_tr.reshape(-1, 1))  #reshape only because fit needs a 2d array\n",
    "    x_scaler.append(x_sc)\n",
    "    y_scaler.append(y_sc)\n",
    "    \n",
    "    X_train_.append(x_sc.transform(X_tr))\n",
    "    X_test_.append(x_sc.transform(X_t))\n",
    "    y_train_.append(y_sc.transform(y_tr.reshape(-1, 1)))\n",
    "    y_test_.append(y_sc.transform(y_t.reshape(-1, 1)))\n",
    "    \n",
    "    t_train.append(dfs[i].iloc[:int(-n_points_day*val_days)]['date'].values)\n",
    "    t_test.append(dfs[i].iloc[int(-n_points_day*val_days):]['date'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.95\n",
    "p_mean = 50\n",
    "p_lower = ((1.0-alpha)/2.0) * 100\n",
    "p_upper = (alpha+((1.0-alpha)/2.0)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all = []\n",
    "lower_all = []\n",
    "upper_all = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(n_sets):\n",
    "    \n",
    "    X_train_i = X_train[i]\n",
    "    y_train_i = y_train[i]\n",
    "    X_test_i = X_test[i]  \n",
    "\n",
    "    n_iterations = 1000\n",
    "    n_train_examples = X_train_i.shape[0]\n",
    "    n_test_examples = X_test_i.shape[0]\n",
    "    n_size = int(n_train_examples * 0.50)\n",
    "    \n",
    "    predictions_all = np.zeros((n_test_examples, n_iterations))  #array to store the various predictions for each model [N_test_point x bootstrap_iterations]\n",
    "\n",
    "    for b in range(n_iterations):\n",
    "        \n",
    "        # prepare train and test sets\n",
    "        x_train_res, y_train_res = resample(X_train_i, y_train_i, n_samples=n_size)\n",
    "        \n",
    "        # fit model\n",
    "        model = DecisionTreeRegressor(max_depth=3)\n",
    "        model.fit(x_train_res, y_train_res)\n",
    "        \n",
    "        # evaluate model\n",
    "        y_first = model.predict(X_test_i[:3])\n",
    "\n",
    "        y_3 = y_first[3-3]\n",
    "        y_2 = y_first[3-2]\n",
    "        y_1 = y_first[3-1]\n",
    "        for j in range(3, X_test[i].shape[0]):\n",
    "            X_test_i[j][-3] = y_3\n",
    "            X_test_i[j][-2] = y_2\n",
    "            X_test_i[j][-1] = y_1\n",
    "            y_pred_j = model.predict(X_test_i[j].reshape(1, -1))\n",
    "            y_3 = y_2\n",
    "            y_2 = y_1\n",
    "            y_1 = y_pred_j\n",
    "        # end of multi-step ahead\n",
    "        \n",
    "        predictions = model.predict(X_test_i)\n",
    "        predictions = y_scaler[i].inverse_transform(predictions.reshape(1, -1))\n",
    "        \n",
    "        predictions_all[:,b] = predictions\n",
    "    \n",
    "    mean = np.zeros((n_test_examples,1))\n",
    "    lower = np.zeros((n_test_examples,1))\n",
    "    upper = np.zeros((n_test_examples,1))\n",
    "    \n",
    "    # Estimate distributions for each time step\n",
    "    for j in range(n_test_examples):\n",
    "        mean[j] = np.percentile(predictions_all[j,:], p_mean) \n",
    "        lower[j] = np.percentile(predictions_all[j,:], p_lower)\n",
    "        upper[j] = np.percentile(predictions_all[j,:], p_upper)\n",
    "        \n",
    "    \n",
    "    mean_all.append(mean)\n",
    "    lower_all.append(lower)\n",
    "    upper_all.append(upper)\n",
    "        \n",
    "end = time.time()\n",
    "# print((end - start)/(len(dfs)))   \n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PICP_func(y, lower, upper):\n",
    "    sum_points = 0\n",
    "    for i, yi in enumerate(y):\n",
    "        if lower[i] <= yi <= upper[i]:\n",
    "            sum_points += 1\n",
    "    \n",
    "    return sum_points / len(y)\n",
    "\n",
    "def PINAW_func(y, lower, upper):\n",
    "    PIAW = np.mean(upper - lower)\n",
    "    R = np.max(y) - np.min(y)\n",
    "    PINAW = PIAW / R\n",
    "    \n",
    "    return PINAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "y_hat = []\n",
    "upper_hat = []\n",
    "lower_hat = []\n",
    "\n",
    "MAE_all = []\n",
    "RMSE_all = []\n",
    "MBE_all = []\n",
    "CRPS_all = []\n",
    "\n",
    "for i in range(n_sets):\n",
    "    \n",
    "    y_test_i = y_test[i]\n",
    "    \n",
    "    mean = mean_all[i]\n",
    "    lower = lower_all[i]\n",
    "    upper = upper_all[i]\n",
    "    \n",
    "    mean = mean.flatten()\n",
    "    lower = lower.flatten()\n",
    "    upper = upper.flatten()\n",
    "    \n",
    "    real_y_test = y_scaler[i].inverse_transform(y_test_i)\n",
    "    real_y_test = real_y_test.flatten()\n",
    "    \n",
    "    \n",
    "    y_hat.append(mean)\n",
    "    y.append(real_y_test)\n",
    "    lower_hat.append(lower)\n",
    "    upper_hat.append(upper)\n",
    "    \n",
    "    # Deterministic metrics\n",
    "    MAE = mean_absolute_error(real_y_test, mean)\n",
    "    RMSE = mean_squared_error(real_y_test, mean, squared=False)\n",
    "    MBE = np.mean(mean - real_y_test)\n",
    "    print(f'MAE: {MAE:.3f}')\n",
    "    print(f'RMSE: {RMSE:.3f}')\n",
    "    print(f'MBE: {MBE:.3f}')\n",
    "    \n",
    "    # Probabilistic metrics\n",
    "    PICP = PICP_func(real_y_test, lower, upper)\n",
    "    PINAW = PINAW_func(real_y_test, lower, upper)\n",
    "    C = prscore.crps_gaussian(real_y_test, mu=mean, sig=(((upper-lower)/4)+0.001))\n",
    "    CRPS = C.mean()\n",
    "    print(f'PICP: {PICP:.3f}')\n",
    "    print(f'PINAW: {PINAW:.3f}')\n",
    "    print(f'CRPS: {CRPS:.3f}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "i = 0  # index of training set\n",
    "\n",
    "k = 0  # index for a spesific day\n",
    "j = list(range((n_points_day*k),n_points_day*(k+7)))  # indeces for one week\n",
    "\n",
    "x = list(range(len(y[i][j])))\n",
    "\n",
    "# Plot predictive means as blue line, observations as gray dots\n",
    "plt.plot(x, y[i][j], 'k', markersize=10, label='Observations')\n",
    "plt.plot(x, y_hat[i][j], 'b-', markersize=10, label='Observations')\n",
    "\n",
    "# plt.plot(lower_hat[i])\n",
    "# plt.plot(upper_hat[i])\n",
    "\n",
    "plt.fill_between(x, lower_hat[i][j], upper_hat[i][j], alpha=0.5, fc='b', ec='None')\n",
    "\n",
    "# plt.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Power')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
