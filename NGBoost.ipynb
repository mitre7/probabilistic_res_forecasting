{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.scores import LogScore, CRPScore\n",
    "from ngboost.distns import Exponential, Normal, LogNormal\n",
    "\n",
    "import time\n",
    "\n",
    "import properscoring as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess  the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('power_weather_data.csv')\n",
    "\n",
    "# csv file MUST contain 'date' and 'Power' fields\n",
    "# optional: weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['date'].apply(lambda x: x.hour )\n",
    "df['month'] = df['date'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = df['Power']\n",
    "\n",
    "PowerData = pd.concat([P.shift(3), P.shift(2), P.shift(1)], axis=1)\n",
    "PowerData.columns = ['t-45', 't-30', 't-15']\n",
    "\n",
    "df = pd.concat([df, PowerData.reindex(df.index)], axis=1)\n",
    "    \n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = [['2018-03-01', '2019-03-15']]\n",
    "\n",
    "val_days = 14\n",
    "\n",
    "n_points_day = 4 * 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for w in weeks:\n",
    "    \n",
    "    w_start = datetime.strptime(w[0]+\" 00:00\", '%Y-%m-%d %H:%M')\n",
    "    w_end = datetime.strptime(w[1]+\" 23:59\", '%Y-%m-%d %H:%M')\n",
    "    \n",
    "    dfs.append(df[(df['date'] > w_start) & (df['date'] < w_end)])\n",
    "    \n",
    "n_sets = len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = []\n",
    "X_test_ = []\n",
    "y_train_ = []\n",
    "y_test_ = []\n",
    "\n",
    "x_scaler = []\n",
    "y_scaler = []\n",
    "\n",
    "t_train = []\n",
    "t_test = []\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "\n",
    "    train = dfs[i][:int(-n_points_day*val_days)]\n",
    "    test = dfs[i][int(-n_points_day*val_days):]\n",
    "    \n",
    "    X_tr = train.drop(['Power','Time'], axis=1).values\n",
    "    X_t = test.drop(['Power','Time'], axis=1).values\n",
    "    \n",
    "    y_tr = train['Power'].values\n",
    "    y_t = test['Power'].values\n",
    "    \n",
    "    x_sc = MinMaxScaler()\n",
    "    y_sc = MinMaxScaler()\n",
    "#     x_sc = StandardScaler()\n",
    "#     y_sc = StandardScaler()\n",
    "    x_sc.fit(X_tr)\n",
    "    y_sc.fit(y_tr.reshape(-1, 1))\n",
    "    x_scaler.append(x_sc)\n",
    "    y_scaler.append(y_sc)\n",
    "    \n",
    "    X_train_.append(x_sc.transform(X_tr))\n",
    "    X_test_.append(x_sc.transform(X_t))\n",
    "    y_train_.append(y_sc.transform(y_tr.reshape(-1, 1)))\n",
    "    y_test_.append(y_sc.transform(y_t.reshape(-1, 1)))\n",
    "    \n",
    "    t_train.append(dfs[i].iloc[:int(-n_points_day*val_days)]['Time'].values)\n",
    "    t_test.append(dfs[i].iloc[int(-n_points_day*val_days):]['Time'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_\n",
    "X_test = X_test_\n",
    "y_train = y_train_\n",
    "y_test = y_test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_learner = DecisionTreeRegressor(\n",
    "    criterion=\"friedman_mse\",\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_depth=3,\n",
    "    splitter=\"best\",\n",
    "    random_state=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngbs = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    \n",
    "    X_train_i = X_train[i]\n",
    "    y_train_i = y_train[i]\n",
    "\n",
    "    ngb = NGBRegressor(Base=tree_learner, n_estimators=1000).fit(X_train_i, y_train_i.ravel())\n",
    "    \n",
    "    ngbs.append(ngb)\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/(len(dfs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PICP_func(y, lower, upper):\n",
    "    sum_points = 0\n",
    "    for i, yi in enumerate(y):\n",
    "        if lower[i] <= yi <= upper[i]:\n",
    "            sum_points += 1\n",
    "    \n",
    "    return sum_points / len(y)\n",
    "\n",
    "def PINAW_func(y, lower, upper):\n",
    "    PIAW = np.mean(upper - lower)\n",
    "    R = np.max(y) - np.min(y)\n",
    "    PINAW = PIAW / R\n",
    "    \n",
    "    return PINAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "y_hat = []\n",
    "upper_hat = []\n",
    "lower_hat = []\n",
    "\n",
    "RMSE_all = []\n",
    "CRPS_all = []\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    \n",
    "    ngb = ngbs[i]\n",
    "    \n",
    "    # For multi-step ahead prediction\n",
    "    y_45 = ngb.pred_dist(X_test[i][0].reshape(1, -1)).params['loc']\n",
    "    y_30 = ngb.pred_dist(X_test[i][1].reshape(1, -1)).params['loc']\n",
    "    y_15 = ngb.pred_dist(X_test[i][2].reshape(1, -1)).params['loc']\n",
    "    for j in range(3, X_test[i].shape[0]):\n",
    "        X_t[j][-3] = y_45\n",
    "        X_t[j][-2] = y_30\n",
    "        X_t[j][-1] = y_15\n",
    "        y_pred_j = ngb.pred_dist(X_test[i][j].reshape(1, -1)).params['loc']\n",
    "        y_45 = y_30\n",
    "        y_30 = y_15\n",
    "        y_15 = y_pred_j\n",
    "    # end of multi-step ahead\n",
    "    \n",
    "    y_pred = ngb.predict(X_train[i])\n",
    "    y_dists = ngb.pred_dist(X_train[i])\n",
    "    \n",
    "    mean = y_dists[:].params['loc']\n",
    "    std = y_dists[:].params['scale']\n",
    "    \n",
    "    mean = y_scaler[i].inverse_transform(mean.reshape(1, -1))\n",
    "    std = y_scaler[i].inverse_transform(std.reshape(1, -1))\n",
    "    \n",
    "    mean = mean.flatten()\n",
    "    std = std.flatten()\n",
    "    \n",
    "    real_y_test = y_scaler[i].inverse_transform(y_train[i])\n",
    "    real_y_test = real_y_test.flatten()\n",
    "    \n",
    "    lower = mean - 1.9600 * std\n",
    "    upper = mean + 1.9600 * std\n",
    "    \n",
    "    y_hat.append(mean)\n",
    "    y.append(real_y_test)\n",
    "    lower_hat.append(lower)\n",
    "    upper_hat.append(upper)\n",
    "    \n",
    "    # Deterministic metrics\n",
    "    MAE = mean_absolute_error(real_y_test, mean)\n",
    "    RMSE = mean_squared_error(real_y_test, mean, squared=False)\n",
    "    MBE = np.mean(mean - real_y_test)\n",
    "    print(f'MAE: {MAE:.3f}')\n",
    "    print(f'RMSE: {RMSE:.3f}')\n",
    "    print(f'MBE: {MBE:.3f}')\n",
    "    \n",
    "    # Probabilistic metrics\n",
    "    PICP = PICP_func(real_y_test, lower[1], upper[1])\n",
    "    PINAW = PINAW_func(real_y_test, lower[1], upper[1])\n",
    "    C = prscore.crps_gaussian(real_y_test, mu=mean, sig=std)\n",
    "    CRPS = C.mean()\n",
    "    print(f'PICP: {PICP:.3f}')\n",
    "    print(f'PINAW: {PINAW:.3f}')\n",
    "    print(f'CRPS: {CRPS:.3f}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "i = 0  # index of training set\n",
    "\n",
    "x = list(range(len(y[i])))\n",
    "\n",
    "# Plot predictive means as blue line, observations as gray dots\n",
    "plt.plot(x, y[i], 'k', markersize=10, label='Observations')\n",
    "plt.plot(x, y_hat[i], 'b-', markersize=10, label='Observations')\n",
    "\n",
    "# plt.plot(lower_hat[i])\n",
    "# plt.plot(upper_hat[i])\n",
    "\n",
    "plt.fill_between(x, lower_hat[i], upper_hat[i], alpha=0.5, fc='b', ec='None')\n",
    "\n",
    "# plt.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "i = 0  # index of training set\n",
    "\n",
    "k = 0  # index for a spesific day\n",
    "j = list(range((n_points_day*k),n_points_day*(k+1)))  # # indeces of that day\n",
    "\n",
    "x = list(range(len(y[i][j])))\n",
    "\n",
    "# Plot predictive means as blue line, observations as gray dots\n",
    "plt.plot(x, y[i][j], 'k', markersize=10, label='Observations')\n",
    "plt.plot(x, y_hat[i][j], 'b-', markersize=10, label='Observations')\n",
    "\n",
    "# plt.plot(lower_hat[i])\n",
    "# plt.plot(upper_hat[i])\n",
    "\n",
    "plt.fill_between(x, lower_hat[i][j], upper_hat[i][j], alpha=0.5, fc='b', ec='None')\n",
    "\n",
    "# plt.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Power')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
